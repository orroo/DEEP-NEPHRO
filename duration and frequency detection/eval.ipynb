{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bdb44fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9d783eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('ready_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f1e5d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TimeSeriesModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, output_size=2, num_layers=1):\n",
    "        super(TimeSeriesModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        # out = out[:, -1, :]\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "55e2a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"overfit_mitigated/xgb_earmy_stopping.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "afec3765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Save the model weights only\n",
    "# torch.save(model.state_dict(), 'try4/model_weights.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2e8fb933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pid', 'datatime', 'sbp', 'dbp', 'temperature', 'conductivity', 'uf',\n",
       "       'blood_flow', 'gender', 'birthday', 'first_dialysis', 'DM', 'keyindate',\n",
       "       'dialysisstart', 'dialysisend', 'weightstart', 'weightend', 'dryweight',\n",
       "       'pulse', 'respiratory_rate', 'blood_oxygen_lvl', 'glucose_lvl',\n",
       "       'hypotension', 'age', 'dialyzer', 'bath', 'technique', 'gain',\n",
       "       'bath_temperature', 'replacement_Volume', 'kt', 'Bath_Flow',\n",
       "       'bicarbonate_conductivity', 'arterial_Pressure', 'Venous_Pressure',\n",
       "       'transmembrane_Pressure', 'avg_weekly_sessions', 'Dialysis_Duration',\n",
       "       'De_hour', 'De_minutes', 'Ds_hour', 'Ds_minutes', 'session_year',\n",
       "       'session_month', 'session_dayofweek', 'session_is_weekend', 'year',\n",
       "       'month', 'dayofweek', 'is_weekend', 'hour', 'minutes', 'fd_year',\n",
       "       'fd_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "56e67abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4c87e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create the profile\n",
    "# profile = ProfileReport(df1, title=\"Dataset Profiling Report\", explorative=True)\n",
    "\n",
    "# # To display it in a Jupyter Notebook:\n",
    "# # profile.to_notebook_iframe()\n",
    "\n",
    "# # OR to save it to an HTML file:\n",
    "# profile.to_file(\"dataset_profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2f748aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df= df1[[\n",
    "    'dbp',\n",
    " 'temperature',\n",
    " 'conductivity',\n",
    " 'gender',\n",
    " 'birthday',\n",
    " 'weightstart',\n",
    " 'weightend',\n",
    " 'dryweight',\n",
    " 'age',\n",
    " 'gain',\n",
    " 'bath_temperature',\n",
    " 'replacement_Volume',\n",
    " 'kt',\n",
    " 'bicarbonate_conductivity',\n",
    " 'Venous_Pressure',\n",
    " 'transmembrane_Pressure',\n",
    " 'avg_weekly_sessions',\n",
    " 'session_year',\n",
    " 'fd_year',\n",
    " 'fd_month']]\n",
    "    # ['sbp', 'dbp', 'temperature', 'conductivity', 'uf',\n",
    "    #    'blood_flow', 'gender', 'birthday', 'DM',\n",
    "    #     'weightstart', 'weightend', 'dryweight',\n",
    "    #    'pulse', 'respiratory_rate', 'blood_oxygen_lvl', 'glucose_lvl',\n",
    "    #    'hypotension', 'age', 'dialyzer', 'bath', 'technique', 'gain',\n",
    "    #    'bath_temperature', 'replacement_Volume', 'kt', 'Bath_Flow',\n",
    "    #    'bicarbonate_conductivity', 'arterial_Pressure', 'Venous_Pressure',\n",
    "    #    'transmembrane_Pressure',\n",
    "    #     'Ds_hour', 'Ds_minutes', 'session_year',\n",
    "    #    'session_month', 'session_dayofweek', 'session_is_weekend', 'year',\n",
    "    #    'month', 'dayofweek', 'is_weekend', 'hour', 'minutes', 'fd_year',\n",
    "    #    'fd_month']]\n",
    "\n",
    "\n",
    "\n",
    "# df1[['sbp','dbp', 'temperature', 'birthday',\n",
    "#        'weightstart', 'weightend', 'dryweight', 'glucose_lvl','age', 'dialyzer',\n",
    "#        'bath_temperature', 'kt','arterial_Pressure','avg_weekly_sessions', 'session_year', 'session_month','fd_year', 'fd_month','year','month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ba464853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48392, 20)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f7636dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.sample(1).to_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f432b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame( df1['Dialysis_Duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9d1a76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y['session'] = df1[ 'avg_weekly_sessions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6a6314a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dialysis_Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48387</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48388</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48389</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48390</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48391</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48392 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dialysis_Duration\n",
       "0                  240.0\n",
       "1                  240.0\n",
       "2                  240.0\n",
       "3                  240.0\n",
       "4                  240.0\n",
       "...                  ...\n",
       "48387              240.0\n",
       "48388              240.0\n",
       "48389              240.0\n",
       "48390              240.0\n",
       "48391              240.0\n",
       "\n",
       "[48392 rows x 1 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171be54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c7a30f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(11, 4, figsize=(20, 20))\n",
    "\n",
    "# axes = axes.flatten()\n",
    "# i=0\n",
    "# for column in test_df.columns:\n",
    "    \n",
    "#     ax = axes[i]\n",
    "#     i+=1\n",
    "#     print(column)\n",
    "#     ax.scatter(test_df[column], Y.Dialysis_Duration)\n",
    "#     ax.set_xlabel(column)\n",
    "#     ax.set_ylabel(\"Dialysis_Duration\")\n",
    "#     ax.set_title(f'cluster : {column}')\n",
    "   \n",
    "#     # print(cluster_df.head(1))\n",
    "#     # Number of features in the dataset\n",
    "\n",
    "\n",
    "\n",
    "# # Adjust layout for better spacing\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ec78c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(11, 4, figsize=(30, 30))\n",
    "\n",
    "# axes = axes.flatten()\n",
    "# i=0\n",
    "# for column in test_df.columns:\n",
    "    \n",
    "#     ax = axes[i]\n",
    "#     i+=1\n",
    "#     print(column)\n",
    "#     ax.scatter(test_df[column], Y.session)\n",
    "#     ax.set_xlabel(column)\n",
    "#     ax.set_ylabel(\"Dialysis_Duration\")\n",
    "#     ax.set_title(f'cluster : {column}')\n",
    "   \n",
    "#     # print(cluster_df.head(1))\n",
    "#     # Number of features in the dataset\n",
    "\n",
    "\n",
    "\n",
    "# # Adjust layout for better spacing\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac44192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "847bbb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([240., 243., 259., 230., 233., 242., 232., 236., 229., 231., 246.,\n",
       "       237., 235., 248., 273., 239., 217., 245., 238., 244., 203., 210.,\n",
       "       216., 180., 251., 223., 218., 250., 241., 228., 234., 220., 214.,\n",
       "       247., 227., 222., 249., 120., 226., 213., 252., 258., 254., 205.,\n",
       "       300., 253., 224., 268., 270., 219., 221., 190., 262., 202., 260.,\n",
       "       184., 256., 540., 211., 225., 207., 185., 212., 850., 263., 200.,\n",
       "       204., 168., 174., 206., 188., 191., 171., 182., 183., 208., 215.,\n",
       "       209., 255., 155., 167., 162., 153., 106., 150., 156., 144., 170.,\n",
       "       141., 165., 124., 122., 169., 157., 151., 197., 179., 140., 154.,\n",
       "       145., 186., 181., 277., 281., 269., 267., 264., 257., 261., 292.,\n",
       "       279., 265., 346., 283., 280., 266., 275.,  60., 282., 315., 295.,\n",
       "       291., 193., 360., 271., 840., 272., 199., 285.])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.Dialysis_Duration.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "78233fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(test_df, Y, test_size=0.1, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "afc2c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c0a61c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.score(X_test, y_test)\n",
    "# print(f\"- R² score on test data: {score:.4f}\")\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "# print(f\"- RMSE score on test data: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "597d242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# scaler =joblib.load(\"last try 2\\scalerX.pkl\")\n",
    "# scaler_y =joblib.load(\"last try 2\\scalerY.pkl\")\n",
    "\n",
    "X_train_scaled = X_train\n",
    "# scaler.transform(X_train)\n",
    "X_val_scaled = X_test\n",
    "# scaler.transform(X_test)\n",
    "Y_train_scaled = y_train\n",
    "# scaler_y.transform(y_train)\n",
    "Y_val_scaled = y_test\n",
    "# scaler_y.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dfb646b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# Create datasets and loaders\n",
    "import torch\n",
    "\n",
    "# /*************  ✨ Windsurf Command ⭐  *************/\n",
    "# X_train_scaled = X_train_scaled.values\n",
    "# X_val_scaled = X_val_scaled.values\n",
    "# /*******  f52b8168-83a6-4692-b086-21b9d381d329  *******/\n",
    "X_train_test = torch.tensor(X_train_scaled.values, dtype=torch.float32)\n",
    "y_train_test = torch.tensor(Y_train_scaled.values, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_test, y_train_test)\n",
    "\n",
    "\n",
    "X_val_test = torch.tensor(X_val_scaled.values, dtype=torch.float32)\n",
    "y_val_test = torch.tensor(Y_val_scaled.values, dtype=torch.float32)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_test, y_val_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ba85289e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# /*************  ✨ Windsurf Command 🌟  *************/\n",
    "# model.val()\n",
    "\n",
    "# def get_model_features(model):\n",
    "#     \"\"\"Get the feature names input to a model.\"\"\"\n",
    "#     if hasattr(model, 'feature_names_in_'):\n",
    "#         return model.feature_names_in_\n",
    "#     elif hasattr(model, 'feature_names_'):\n",
    "#         return model.feature_names_\n",
    "#     else:\n",
    "#         raise ValueError('Model does not have feature names attribute.')\n",
    "# /*******  73c4631c-43b3-4abd-bf4c-840c351681c0  *******/\n",
    "\n",
    "# /*************  ✨ Windsurf Command ⭐  *************/\n",
    "# # Get the feature names from the model\n",
    "# feature_names = model.get_booster().feature_names\n",
    "# /*******  16ddaab3-2662-43ae-87d6-55c231cb04f8  *******/\n",
    "\n",
    "\n",
    "len(model.get_booster().feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4390decf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dbp', 'temperature', 'conductivity', 'gender', 'birthday',\n",
       "       'weightstart', 'weightend', 'dryweight', 'age', 'gain',\n",
       "       'bath_temperature', 'replacement_Volume', 'kt',\n",
       "       'bicarbonate_conductivity', 'Venous_Pressure', 'transmembrane_Pressure',\n",
       "       'avg_weekly_sessions', 'session_year', 'fd_year', 'fd_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256dd444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b6554b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.6000e+01, 3.6000e+01, 1.4000e+01,  ..., 2.0130e+03, 2.0110e+03,\n",
      "         1.0000e+00],\n",
      "        [5.7000e+01, 3.7000e+01, 1.3900e+01,  ..., 2.0180e+03, 2.0040e+03,\n",
      "         2.0000e+00],\n",
      "        [7.2000e+01, 3.6500e+01, 1.4100e+01,  ..., 2.0140e+03, 2.0140e+03,\n",
      "         2.0000e+00],\n",
      "        ...,\n",
      "        [6.0000e+01, 3.6500e+01, 1.4000e+01,  ..., 2.0160e+03, 2.0120e+03,\n",
      "         6.0000e+00],\n",
      "        [5.0000e+01, 3.6000e+01, 1.4100e+01,  ..., 2.0170e+03, 2.0020e+03,\n",
      "         9.0000e+00],\n",
      "        [6.3000e+01, 3.6000e+01, 1.4700e+01,  ..., 2.0150e+03, 2.0130e+03,\n",
      "         5.0000e+00]])\n",
      "MAE: 0.4298628728251812\n",
      "RMSE: 2.147489642087348\n",
      "R² Score: 0.9589750170707703\n"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    X_val_test = torch.tensor(X_val_scaled.values, dtype=torch.float32)\n",
    "    print( X_val_test)\n",
    "    preds = model.predict(X_test)\n",
    "    # preds = scaler_y.inverse_transform(preds)  # Convert back to real values\n",
    "    y_val_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "    actuals =y_test\n",
    "    \n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(actuals, preds))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(actuals, preds)))\n",
    "print(\"R² Score:\", r2_score(actuals, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "320e8fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dialysis_Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39356</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19658</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22983</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40594</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24601</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46174</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4840 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dialysis_Duration\n",
       "4132               241.0\n",
       "6120               240.0\n",
       "39356              240.0\n",
       "19658              240.0\n",
       "22983              240.0\n",
       "...                  ...\n",
       "2693               240.0\n",
       "6639               240.0\n",
       "40594              240.0\n",
       "24601              240.0\n",
       "46174              240.0\n",
       "\n",
       "[4840 rows x 1 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "90f14dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([240.66438, 240.20535, 240.13   , ..., 240.1355 , 240.76378,\n",
       "       240.4559 ], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2f5b3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# model.eval()\n",
    "# test_preds = []\n",
    "# test_targets = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for X_batch, y_batch in val_loader:  # Assuming you have a test DataLoader\n",
    "#         outputs = model(X_batch)\n",
    "#         test_preds.append(outputs.cpu())\n",
    "#         test_targets.append(y_batch.cpu())\n",
    "\n",
    "# test_preds = torch.cat(test_preds).numpy()\n",
    "# test_targets = torch.cat(test_targets).numpy()\n",
    "\n",
    "# mae = mean_absolute_error(test_targets, test_preds)\n",
    "# r2 = r2_score(test_targets, test_preds)\n",
    "\n",
    "# print(f\"Test MAE: {mae:.4f}, Test R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "91a02712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4dc07b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fcb66962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Assuming your model and DataLoader are ready\n",
    "# # For example, let's assume you have a trained model and a dataloader (e.g., test_loader)\n",
    "# # Your model should be in eval mode to avoid unnecessary changes during inference\n",
    "# model.eval()\n",
    "\n",
    "# # Take one batch from your dataloader (let's assume it's a single batch)\n",
    "# # Make sure you take one sample, not the whole batch (if you want to explain individual predictions)\n",
    "# data_iter = iter(val_loader)\n",
    "# inputs, labels = next(data_iter)\n",
    "\n",
    "# # Get a single sample to explain (batch size = 1)\n",
    "# sample_input = inputs[0].unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# # Create a SHAP explainer for your model using DeepExplainer (for PyTorch models)\n",
    "# # Here we use a small batch from the dataset to initialize the explainer\n",
    "# background_data = inputs[:100]  # You can use a few samples from the dataset for the background\n",
    "# explainer = shap.Explainer(model, background_data)\n",
    "\n",
    "# # Now calculate SHAP values for the single sample\n",
    "# single_shap_value = explainer.shap_values(sample_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "46487e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_booster()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b20c3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: grab a few samples from the training dataloader\n",
    "# background_samples = [X_test.values]\n",
    "# # for batch in train_loader:  # assuming your DataLoader is called train_loader\n",
    "# #     inputs, _ = batch\n",
    "# #     background_samples.append(inputs)\n",
    "# #     if len(background_samples) >= 2:  # Take 2 batches, for example\n",
    "# #         break\n",
    "\n",
    "# # # background = torch.cat(X_train, dim=0)  # Concatenate into one tensor\n",
    "# # background = torch.cat([x.to(next(model.get_booster()).device) for x in background_samples], dim=0)\n",
    "# # background = background.to(next(model.get_booster()).device)  # Move to same device as model\n",
    "\n",
    "# # /*************  ✨ Windsurf Command ⭐  *************/\n",
    "# background = torch.cat(background_samples, dim=0)  # Concatenate into one tensor\n",
    "# background = background.to(next(model.parameters()).device)  # Move to same device as model\n",
    "\n",
    "# /*************  ✨ Windsurf Command ⭐  *************/\n",
    "# # Fix for XGBRegressor which doesn't have a `parameters()` method\n",
    "# if hasattr(model, 'parameters'):\n",
    "#     background = background.to(next(model.parameters()).device)\n",
    "# else:\n",
    "#     background = background.to('cpu')  # Default to CPU if not found\n",
    "# /*******  4a1768cf-dab9-49b7-8152-590628caddc5  *******/\n",
    "\n",
    "\n",
    "background_samples = [torch.tensor(x, dtype=torch.float32) for x in X_test.values]\n",
    "\n",
    "# Concatenate tensors into one tensor\n",
    "background = torch.cat(background_samples, dim=0)\n",
    "\n",
    "# Move to the same device as the model\n",
    "background = background.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ef6e4fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96800])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "918814f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  76.,   36.,   14.,  ..., 2015., 2013.,    5.])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "adfd7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: grab a few samples from the test dataloader\n",
    "# test_samples = []\n",
    "# for batch in val_loader:  # assuming your test DataLoader is called test_loader\n",
    "#     inputs, _ = batch\n",
    "#     test_samples.append(inputs)\n",
    "#     if len(test_samples) >= 1:  # Take 1 batch, for example\n",
    "#         break\n",
    "\n",
    "# test_samples = torch.cat(test_samples, dim=0)\n",
    "# test_samples = test_samples.to(next(model.parameters()).device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_samples = [torch.tensor(x, dtype=torch.float32) for x in X_test.values]\n",
    "\n",
    "# Concatenate tensors into one tensor\n",
    "test_samples = torch.cat(test_samples, dim=0)\n",
    "\n",
    "# Move to the same device as the model\n",
    "test_samples = background.to('cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "33c57988",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[23:40:57] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api_utils.h:129: Check failed: std::accumulate(shape.cbegin(), shape.cend(), static_cast<bst_ulong>(1), std::multiplies<>{}) == chunksize * rows (193600 vs. 2032800) : ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# test_samples = test_samples.reshape(-1, test_samples.shape[-1])  # reshape to 2D\u001b[39;00m\n\u001b[0;32m     12\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mTreeExplainer (model)  \u001b[38;5;66;03m# use a small sample for background\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m# explain on a few test samples\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# /*************  ✨ Windsurf Command ⭐  *************/\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#         test_samples = test_samples.reshape(-1, test_samples.shape[-1])  # reshape to 2D\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# /*******  6155c70c-bf42-4fb3-ba3a-d489c42235bb  *******/\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\shap\\explainers\\_tree.py:565\u001b[0m, in \u001b[0;36mTreeExplainer.shap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[0;32m    563\u001b[0m     dmatrix_props \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_xgb_dmatrix_props\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m    564\u001b[0m     X \u001b[38;5;241m=\u001b[39m xgboost\u001b[38;5;241m.\u001b[39mDMatrix(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdmatrix_props)\n\u001b[1;32m--> 565\u001b[0m phi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_contribs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapprox_contribs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapproximate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_additivity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    573\u001b[0m     model_output_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39moriginal_model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    574\u001b[0m         X, iteration_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_iterations), output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, validate_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\core.py:2527\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, output_margin, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[0;32m   2525\u001b[0m shape \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mPOINTER(c_bst_ulong)()\n\u001b[0;32m   2526\u001b[0m dims \u001b[38;5;241m=\u001b[39m c_bst_ulong()\n\u001b[1;32m-> 2527\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2528\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterPredictFromDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2529\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_pystr_to_cstr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\core.py:310\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [23:40:57] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api_utils.h:129: Check failed: std::accumulate(shape.cbegin(), shape.cend(), static_cast<bst_ulong>(1), std::multiplies<>{}) == chunksize * rows (193600 vs. 2032800) : "
     ]
    }
   ],
   "source": [
    "# Explainability setup\n",
    "# /*************  ✨ Windsurf Command ⭐  *************/\n",
    "# # GradientExplainer currently only works with PyTorch or TensorFlow models\n",
    "# # If you have an XGBoost model, you can use the TreeExplainer instead\n",
    "# if isinstance(model, xgboost.sklearn.XGBRegressor):\n",
    "#     explainer = shap.TreeExplainer(model)\n",
    "# else:\n",
    "#     explainer = shap.GradientExplainer (model, background)\n",
    "# /*******  5b4673b0-4b8d-49c9-a730-ee9e1c6f0bdc  *******/\n",
    "test_samples = test_samples.reshape(test_samples.shape[0], -1)\n",
    "# test_samples = test_samples.reshape(-1, test_samples.shape[-1])  # reshape to 2D\n",
    "explainer = shap.TreeExplainer (model)  # use a small sample for background\n",
    "shap_values = explainer.shap_values(test_samples, check_additivity=False)     # explain on a few test samples\n",
    "\n",
    "# /*************  ✨ Windsurf Command ⭐  *************/\n",
    "#         test_samples = test_samples.reshape(-1, test_samples.shape[-1])  # reshape to 2D\n",
    "# /*******  6155c70c-bf42-4fb3-ba3a-d489c42235bb  *******/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2360eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names\n",
    "feature_names = ['sbp', 'dbp', 'temperature', 'conductivity', 'uf',\n",
    "       'blood_flow', 'gender', 'birthday', 'DM',\n",
    "        'weightstart', 'weightend', 'dryweight',\n",
    "       'pulse', 'respiratory_rate', 'blood_oxygen_lvl', 'glucose_lvl',\n",
    "       'hypotension', 'age', 'dialyzer', 'bath', 'technique', 'gain',\n",
    "       'bath_temperature', 'replacement_Volume', 'kt', 'Bath_Flow',\n",
    "       'bicarbonate_conductivity', 'arterial_Pressure', 'Venous_Pressure',\n",
    "       'transmembrane_Pressure',\n",
    "        'Ds_hour', 'Ds_minutes', 'session_year',\n",
    "       'session_month', 'session_dayofweek', 'session_is_weekend', 'year',\n",
    "       'month', 'dayofweek', 'is_weekend', 'hour', 'minutes', 'fd_year',\n",
    "       'fd_month']  # replace with your real feature names\n",
    "\n",
    "# Plot summary of feature importances\n",
    "shap.summary_plot(shap_values[:,:,0], test_samples,plot_type=\"bar\",plot_size=0.2, feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb450fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap.summary_plot(shap_values[:,:,1], test_samples,plot_type=\"bar\",plot_size=0.2, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa6b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.decision_plot(explainer.expected_value[1], shap_values[1], feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Pick a single patient\n",
    "patient_idx = 0  # for the first patient\n",
    "patient_input = test_samples\n",
    "print(patient_input.shape)\n",
    "# Compute SHAP values for just that one patient\n",
    "single_shap_value = explainer.shap_values(patient_input, check_additivity=False)\n",
    "print(single_shap_value[0].shape)\n",
    "\n",
    "shap_values_for_class = single_shap_value[0][:, patient_idx]\n",
    "print(shap_values_for_class.shape)\n",
    "# Plot the force plot\n",
    "# shap.initjs()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    explainer.expected_value[0], \n",
    "    shap_values_for_class,  # ← single sample\n",
    "    patient_input[0].cpu().numpy(),  # ← features for that sample\n",
    "    feature_names=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_input.cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SHAP values for class 0 (shape should be (n_samples, n_features))\n",
    "shap_values_class_0 = shap_values[0]  # Assuming shape (1, 44, 2)\n",
    "\n",
    "# For a single sample, select the first sample's SHAP values for class 0\n",
    "shap_values_for_plot = shap_values[0:32, :, 0]  # Shape (1, 44)\n",
    "\n",
    "# Get the corresponding features (must be 2D)\n",
    "features_for_plot = patient_input.cpu().numpy() # Shape (1, 44)\n",
    "\n",
    "# Now plot the dependence plot\n",
    "shap.dependence_plot(\n",
    "    43,  # Feature index to plot\n",
    "    shap_values_for_plot, \n",
    "    features_for_plot,\n",
    "    feature_names=feature_names,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a 2x2 grid for subplots\n",
    "fig, axes = plt.subplots(11, 4, figsize=(20, 20))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range (len(feature_names)):\n",
    "    # print(f\"Cluster {cluster_id} DataFrame:\")\n",
    "    ax = axes[i]\n",
    "    shap.dependence_plot(\n",
    "    i,  # Feature index to plot\n",
    "    shap_values_for_plot, \n",
    "    features_for_plot,\n",
    "    feature_names=feature_names,\n",
    "    ax=axes[i],\n",
    "    show=False\n",
    "\n",
    ")\n",
    "    # Number of features in the dataset\n",
    "\n",
    "\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b86bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "background.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8409fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5135617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lime import lime_tabular\n",
    "\n",
    "# Define prediction function\n",
    "def predict_fn(x):\n",
    "    x_tensor = torch.tensor(x, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(x_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "    return probs.numpy()\n",
    "\n",
    "back = pd.DataFrame(background , columns=feature_names)\n",
    "# Create explainer\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=back.values,\n",
    "    feature_names=back.columns.tolist(),\n",
    "    mode='regression'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explain a prediction\n",
    "i = 20  # Example index\n",
    "test_sc=scaler.inverse_transform(test_samples)\n",
    "test = pd.DataFrame(test_sc , columns=feature_names)\n",
    "\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=test.iloc[i].values,\n",
    "    predict_fn=predict_fn,\n",
    "    num_features=20\n",
    ")\n",
    "\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35538677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.initjs()\n",
    "# shap.plots.waterfall(shap_values[:,:,0])  # First sample, first class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(shap_values[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.waterfall(\n",
    "#     shap_values[0],  # SHAP values for the sample and class\n",
    "#     max_display=12,  # Limit the number of features shown\n",
    "#     show=True        # Display the plot\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde0f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Shape of patient_input[0]:\", patient_input[0].cpu().numpy().shape)\n",
    "# print(\"Shape of single_shap_value[0][0]:\", single_shap_value[0][0].shape)\n",
    "# print(\"Length of feature_names:\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Model output for a patient:\", model(patient_input).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db361aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# # Sauvegarder le modèle\n",
    "# joblib.dump(model, 'last try 2\\\\cnn_try_data_final sampling_50k 96.pkl')\n",
    "# print(\"Modèle enregistré sous le nom 'random_forest_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9facd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold, cross_val_score\n",
    "# from sklearn.metrics import mean_squared_error, make_scorer\n",
    "# # Use KFold with 5 splits\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Use negative RMSE as a scoring function (because sklearn is annoying)\n",
    "# neg_rmse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# # cross_val_score returns NEGATIVE MSE values, so we negate and sqrt for RMSE\n",
    "# scores = cross_val_score(model, test_df, Y, cv=kf, scoring=neg_rmse)\n",
    "# rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "# print(\"RMSE scores:\", rmse_scores)\n",
    "# print(\"Average RMSE:\", np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Assume you've trained the model\n",
    "# train_preds = model.predict(X_train)\n",
    "# test_preds = model.predict(X_test)\n",
    "\n",
    "# train_rmse = mean_squared_error(y_train, train_preds, squared=False)\n",
    "# test_rmse = mean_squared_error(y_test, test_preds, squared=False)\n",
    "\n",
    "# train_r2 = r2_score(y_train, train_preds)\n",
    "# test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "# print(f\"Train RMSE: {train_rmse}, Test RMSE: {test_rmse}\")\n",
    "# print(f\"Train R²: {train_r2}, Test R²: {test_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830bc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import learning_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(\n",
    "#     model, test_df, Y, cv=5, scoring='neg_mean_squared_error'\n",
    "# )\n",
    "\n",
    "# train_rmse = -train_scores.mean(axis=1) \n",
    "# test_rmse = -test_scores.mean(axis=1) \n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(train_sizes, train_rmse.mean(axis=1), 'o-', label='Training RMSE', color='blue')\n",
    "# plt.plot(train_sizes, test_rmse.mean(axis=1), 'o-', label='Validation RMSE', color='orange')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"Training set size\")\n",
    "# plt.ylabel(\"RMSE\")\n",
    "# plt.title(\"Learning Curve\")\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
